{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Cost-Functions-and-Solutions-To-the-Optimization-Problem\" data-toc-modified-id=\"Cost-Functions-and-Solutions-To-the-Optimization-Problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cost Functions and Solutions To the Optimization Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Bad-News\" data-toc-modified-id=\"The-Bad-News-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>The Bad News</a></span></li><li><span><a href=\"#The-Good-News\" data-toc-modified-id=\"The-Good-News-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The Good News</a></span><ul class=\"toc-item\"><li><span><a href=\"#ðŸ§ -Knowledge-Check\" data-toc-modified-id=\"ðŸ§ -Knowledge-Check-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>ðŸ§  Knowledge Check</a></span></li><li><span><a href=\"#More-Log-Loss-Resources\" data-toc-modified-id=\"More-Log-Loss-Resources-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>More Log-Loss Resources</a></span></li></ul></li></ul></li><li><span><a href=\"#Digging-Deeper-into-Logistic-Regression\" data-toc-modified-id=\"Digging-Deeper-into-Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Digging Deeper into Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Data\" data-toc-modified-id=\"Preparing-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Preparing Data</a></span></li><li><span><a href=\"#Train-Logistic-Regression\" data-toc-modified-id=\"Train-Logistic-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train Logistic Regression</a></span></li><li><span><a href=\"#Interpreting-Logistic-Regression-Coefficients\" data-toc-modified-id=\"Interpreting-Logistic-Regression-Coefficients-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Interpreting Logistic Regression Coefficients</a></span></li></ul></li><li><span><a href=\"#Putting-It-All-Together:-Training-Logistic-Regression\" data-toc-modified-id=\"Putting-It-All-Together:-Training-Logistic-Regression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Putting It All Together: Training Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-and-Explore-Data\" data-toc-modified-id=\"Load-and-Explore-Data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load and Explore Data</a></span></li><li><span><a href=\"#Create-and-Train-Logistic-Regression-Model\" data-toc-modified-id=\"Create-and-Train-Logistic-Regression-Model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Create and Train Logistic Regression Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional:-Evaluate-the-Model-with-Cross-Validation\" data-toc-modified-id=\"Optional:-Evaluate-the-Model-with-Cross-Validation-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Optional: Evaluate the Model with Cross-Validation</a></span></li><li><span><a href=\"#Optional:-Rinse-and-Repeat---Multiple-Models\" data-toc-modified-id=\"Optional:-Rinse-and-Repeat---Multiple-Models-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Optional: Rinse and Repeat - Multiple Models</a></span></li></ul></li><li><span><a href=\"#Final-Evaluation\" data-toc-modified-id=\"Final-Evaluation-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Final Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Set\" data-toc-modified-id=\"Training-Set-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Training Set</a></span></li><li><span><a href=\"#Testing-Set\" data-toc-modified-id=\"Testing-Set-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Testing Set</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#Level-Up\" data-toc-modified-id=\"Level-Up-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up</a></span><ul class=\"toc-item\"><li><span><a href=\"#More-Generalizations:-Other-Link-Functions,-Other-Models\" data-toc-modified-id=\"More-Generalizations:-Other-Link-Functions,-Other-Models-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>More Generalizations: Other Link Functions, Other Models</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "\n",
    "Because it doesn't make senst to do a linear regression against the class labels of 0 and 1, we instead do a linear regression against what transformation of y, where y is our 0's and 1's?\n",
    "- logit function: the logarithm of the odds of y\n",
    "- ln (y / 1-y) <br> \n",
    "\n",
    "How do we transform our predicted log odds of y into predicted probabilities of y?\n",
    "- sigmoid function <br> \n",
    "\n",
    "What is the relationship between the logit function and the sigmoid function?\n",
    "- inverse of each other <br> \n",
    "\n",
    "What is the cost function we use for logistic regression?\n",
    "- log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For our modeling steps\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# For demonstrative purposes\n",
    "from scipy.special import logit, expit\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Explain the form of logistic regression\n",
    "- Explain how to interpret logistic regression coefficients\n",
    "- Use logistic regression to perform a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cost Functions and Solutions To the Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unlike the least-squares problem for linear regression, no one has yet found a closed-form solution to the optimization problem presented by logistic regression. But even if one exists, the computation would no doubt be so complex that we'd be better off using some sort of approximation method instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But there's still a problem.\n",
    "\n",
    "Recall the cost function for linear regression: <br/><br/>\n",
    "$SSE = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i(y_i - (\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in}))^2$.\n",
    "\n",
    "This function, $SSE(\\vec{\\beta})$, is convex.\n",
    "\n",
    "If we plug in our new logistic equation for $\\hat{y}$, we get: <br/><br/>\n",
    "$SSE_{log} = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i\\left(y_i - \\left(\\frac{1}{1+e^{-(\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in})}}\\right)\\right)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Bad News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*This* function, $SSE_{log}(\\vec{\\beta})$, is [**not** convex](https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c).\n",
    "\n",
    "That means that, if we tried to use gradient descent or some other approximation method that looks for the minimum of this function, we could easily find a local rather than a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note that the scikit-learn class *expects the user to specify the solver* to be used in calculating the coefficients. The default solver, [lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS), works well for many applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Good News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use **log-loss** instead:\n",
    "\n",
    "$\\mathcal{L}(\\vec{y}, \\hat{\\vec{y}}) = -\\frac{1}{N}\\Sigma^N_{i=1}\\left(y_iln(\\hat{y}_i)+(1-y_i)ln(1-\\hat{y}_i)\\right)$,\n",
    "\n",
    "where $\\hat{y}_i$ is the probability that $(x_{i1}, ... , x_{in})$ belongs to **class 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**More resources on the log-loss function**:\n",
    "\n",
    "https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ðŸ§  Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Is a bigger value (more positive) better or worse than a smaller value? <br>Worse!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data point:\n",
    "    #target value is 0\n",
    "    #predicted value is 1\n",
    "    #predicted probability of it being 1 is .9\n",
    "    #predicted probability of it eing 0 is .1\n",
    "    \n",
    "    # -ln(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### More Log-Loss Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Digging Deeper into Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type\n",
       "id                                                                        \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1\n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6\n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glass identification dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass.sort_values('al', inplace=True)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  \n",
       "id              \n",
       "22           0  \n",
       "185          1  \n",
       "40           0  \n",
       "39           0  \n",
       "51           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types 1, 2, 3 are window glass\n",
    "# types 5, 6, 7 are household glass\n",
    "glass['household'] = glass.glass_type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "X = glass[['al']]\n",
    "y = glass ['household']\n",
    "logreg.fit(X,y)\n",
    "glass['household_pred_class'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions of X (0s and 1s), NOT predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.361506808726077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the log loss\n",
    "#need to get predicted probabilities\n",
    "logreg.predict_proba(X)\n",
    "\n",
    "log_loss(y, logreg.predict_proba(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.361506808726077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean([y*np.log(y_hat) + (1-y)*np.log(1-y_hat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Interpreting Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.11517927]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get our logistic regression coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every one unit increase in alumninum content increases the odds of the glass being a household glass by e^3.12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### How do we interpret the coefficients of a logistic regression? For a linear regression, the situaton was like this:\n",
    "\n",
    "- Linear Regression: We construct the best-fit line and get a set of coefficients. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change in $y$.\n",
    "\n",
    "- Logistic Regression: We find the coefficients of the best-fit line by some approximation method. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change (not in $y$ but) in $ln\\left(\\frac{y}{1-y}\\right)$.\n",
    "\n",
    "We have:\n",
    "\n",
    "$\\ln\\left(\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}\\right) = \\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k$.\n",
    "\n",
    "Exponentiating both sides:\n",
    "\n",
    "$\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)} = e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k}$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right)}\\cdot e^k$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^k\\cdot\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}$\n",
    "\n",
    "That is, the odds ratio at $x_1+1$ has increased by a factor of $e^k$ relative to the odds ratio at $x_1$.\n",
    "\n",
    "For more on interpretation, see [this page](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/binary-logistic-regression/interpret-the-results/all-statistics-and-graphs/coefficients/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00934605])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** For an 'al' value of 0, the log-odds of 'household' is -6.01. What is the probability that glass with an 'al' value of 0 is household glass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00244968])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to probability\n",
    "\n",
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# examine the coefficient for al\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mfeature_cols\u001b[49m, logreg\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# examine the coefficient for al\n",
    "\n",
    "list(zip(feature_cols, logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** A 1 unit increase in 'al' is associated with a 3.12-unit increase in the log-odds of 'household'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Verifying log-odds to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's verify this as we change the aluminum content from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94755733, 0.05244267]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=1\n",
    "\n",
    "pred_al1 = logreg.predict_proba([[1]])\n",
    "pred_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05534512023573517"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=1\n",
    "\n",
    "odds_al1 = pred_al1[0][1] / pred_al1[0][0]\n",
    "odds_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4449707, 0.5550293]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=2\n",
    "pred_al2 = logreg.predict_proba([[2]])\n",
    "pred_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2473390003597828"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=2\n",
    "\n",
    "odds_al2 = pred_al2[0][1] / pred_al2[0][0]\n",
    "odds_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2473390003597824\n",
      "1.2473390003597828\n"
     ]
    }
   ],
   "source": [
    "print((np.exp(logreg.coef_[0]) * odds_al1)[0])\n",
    "print(odds_al2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Use Coefficients to Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22101248])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute predicted log-odds for al=2 using the equation\n",
    "x_al = 2\n",
    "logodds = logreg.intercept_ + logreg.coef_[0] * x_al\n",
    "logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.247339])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to odds\n",
    "\n",
    "odds = np.exp(logodds)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5550293])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert odds to probability\n",
    "\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute predicted probability for al=2 using the predict_proba method\n",
    "\n",
    "logreg.predict_proba(np.array([2.0]).reshape(1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Putting It All Together: Training Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take some time to show how you can do use logistic regression in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note we've been talking about _binary classification_ but we can also do classification for _multiclass_ problems (more than binary classes).\n",
    ">\n",
    "> That's what we'll do for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Built in dataset from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[iris['data'], iris['target']],\n",
    "    columns=iris['feature_names'] + ['target']\n",
    ")\n",
    "\n",
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how many different targets there are\n",
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can go ahead and explore some graphs to show that it doesn't make sense to do a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating a large figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Iterating over the different\n",
    "for i in range(0, 4):\n",
    "    # Figure number starts at 1\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    # Add a title to make it clear what each subplot shows\n",
    "    plt.title(df.columns[i])\n",
    "    # Use alpha to better see crossing pints\n",
    "    ax.scatter(df['target'], df.iloc[:, i], c='teal', alpha=0.1)\n",
    "    # Only show the tick marks for each target\n",
    "    plt.xticks(df.target.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Preparing the data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the features and then the target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ],\n",
       "       [0.78417499, 0.5663486 , 0.2468699 , 0.05808704],\n",
       "       [0.78010936, 0.57660257, 0.23742459, 0.0508767 ],\n",
       "       [0.80218492, 0.54548574, 0.24065548, 0.0320874 ],\n",
       "       [0.80642366, 0.5315065 , 0.25658935, 0.03665562],\n",
       "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
       "       [0.80373519, 0.55070744, 0.22325977, 0.02976797],\n",
       "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
       "       [0.82307218, 0.51442011, 0.24006272, 0.01714734],\n",
       "       [0.8025126 , 0.55989251, 0.20529392, 0.01866308],\n",
       "       [0.81120865, 0.55945424, 0.16783627, 0.02797271],\n",
       "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
       "       [0.79428944, 0.57365349, 0.19121783, 0.05883625],\n",
       "       [0.80327412, 0.55126656, 0.22050662, 0.04725142],\n",
       "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
       "       [0.77964883, 0.58091482, 0.22930848, 0.0458617 ],\n",
       "       [0.8173379 , 0.51462016, 0.25731008, 0.03027177],\n",
       "       [0.78591858, 0.57017622, 0.23115252, 0.06164067],\n",
       "       [0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
       "       [0.80597792, 0.52151512, 0.26865931, 0.07901744],\n",
       "       [0.776114  , 0.54974742, 0.30721179, 0.03233808],\n",
       "       [0.82647451, 0.4958847 , 0.26447184, 0.03305898],\n",
       "       [0.79778206, 0.5424918 , 0.25529026, 0.06382256],\n",
       "       [0.80641965, 0.54278246, 0.23262105, 0.03101614],\n",
       "       [0.81609427, 0.5336001 , 0.21971769, 0.03138824],\n",
       "       [0.79524064, 0.54144043, 0.27072022, 0.03384003],\n",
       "       [0.80846584, 0.52213419, 0.26948861, 0.03368608],\n",
       "       [0.82225028, 0.51771314, 0.22840286, 0.06090743],\n",
       "       [0.76578311, 0.60379053, 0.22089897, 0.0147266 ],\n",
       "       [0.77867447, 0.59462414, 0.19820805, 0.02831544],\n",
       "       [0.81768942, 0.51731371, 0.25031309, 0.03337508],\n",
       "       [0.82512295, 0.52807869, 0.19802951, 0.03300492],\n",
       "       [0.82699754, 0.52627116, 0.19547215, 0.03007264],\n",
       "       [0.78523221, 0.5769053 , 0.22435206, 0.01602515],\n",
       "       [0.80212413, 0.54690282, 0.23699122, 0.03646019],\n",
       "       [0.80779568, 0.53853046, 0.23758697, 0.03167826],\n",
       "       [0.80033301, 0.56023311, 0.20808658, 0.04801998],\n",
       "       [0.86093857, 0.44003527, 0.24871559, 0.0573959 ],\n",
       "       [0.78609038, 0.57170209, 0.23225397, 0.03573138],\n",
       "       [0.78889479, 0.55222635, 0.25244633, 0.09466737],\n",
       "       [0.76693897, 0.57144472, 0.28572236, 0.06015208],\n",
       "       [0.82210585, 0.51381615, 0.23978087, 0.05138162],\n",
       "       [0.77729093, 0.57915795, 0.24385598, 0.030482  ],\n",
       "       [0.79594782, 0.55370283, 0.24224499, 0.03460643],\n",
       "       [0.79837025, 0.55735281, 0.22595384, 0.03012718],\n",
       "       [0.81228363, 0.5361072 , 0.22743942, 0.03249135],\n",
       "       [0.76701103, 0.35063361, 0.51499312, 0.15340221],\n",
       "       [0.74549757, 0.37274878, 0.52417798, 0.17472599],\n",
       "       [0.75519285, 0.33928954, 0.53629637, 0.16417236],\n",
       "       [0.75384916, 0.31524601, 0.54825394, 0.17818253],\n",
       "       [0.7581754 , 0.32659863, 0.5365549 , 0.17496355],\n",
       "       [0.72232962, 0.35482858, 0.57026022, 0.16474184],\n",
       "       [0.72634846, 0.38046824, 0.54187901, 0.18446945],\n",
       "       [0.75916547, 0.37183615, 0.51127471, 0.15493173],\n",
       "       [0.76301853, 0.33526572, 0.53180079, 0.15029153],\n",
       "       [0.72460233, 0.37623583, 0.54345175, 0.19508524],\n",
       "       [0.76923077, 0.30769231, 0.53846154, 0.15384615],\n",
       "       [0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
       "       [0.78892752, 0.28927343, 0.52595168, 0.13148792],\n",
       "       [0.73081412, 0.34743622, 0.56308629, 0.16772783],\n",
       "       [0.75911707, 0.3931142 , 0.48800383, 0.17622361],\n",
       "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
       "       [0.70631892, 0.37838513, 0.5675777 , 0.18919257],\n",
       "       [0.75676497, 0.35228714, 0.53495455, 0.13047672],\n",
       "       [0.76444238, 0.27125375, 0.55483721, 0.18494574],\n",
       "       [0.76185188, 0.34011245, 0.53057542, 0.14964948],\n",
       "       [0.6985796 , 0.37889063, 0.56833595, 0.21312598],\n",
       "       [0.77011854, 0.35349703, 0.50499576, 0.16412362],\n",
       "       [0.74143307, 0.29421947, 0.57667016, 0.17653168],\n",
       "       [0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
       "       [0.76741698, 0.34773582, 0.51560829, 0.15588157],\n",
       "       [0.76785726, 0.34902603, 0.51190484, 0.16287881],\n",
       "       [0.76467269, 0.31486523, 0.53976896, 0.15743261],\n",
       "       [0.74088576, 0.33173989, 0.55289982, 0.18798594],\n",
       "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
       "       [0.78667474, 0.35883409, 0.48304589, 0.13801311],\n",
       "       [0.76521855, 0.33391355, 0.52869645, 0.15304371],\n",
       "       [0.77242925, 0.33706004, 0.51963422, 0.14044168],\n",
       "       [0.76434981, 0.35581802, 0.51395936, 0.15814134],\n",
       "       [0.70779525, 0.31850786, 0.60162596, 0.1887454 ],\n",
       "       [0.69333409, 0.38518561, 0.57777841, 0.1925928 ],\n",
       "       [0.71524936, 0.40530797, 0.53643702, 0.19073316],\n",
       "       [0.75457341, 0.34913098, 0.52932761, 0.16893434],\n",
       "       [0.77530021, 0.28304611, 0.54147951, 0.15998258],\n",
       "       [0.72992443, 0.39103094, 0.53440896, 0.16944674],\n",
       "       [0.74714194, 0.33960997, 0.54337595, 0.17659719],\n",
       "       [0.72337118, 0.34195729, 0.57869695, 0.15782644],\n",
       "       [0.73260391, 0.36029701, 0.55245541, 0.1681386 ],\n",
       "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
       "       [0.76986879, 0.35413965, 0.5081134 , 0.15397376],\n",
       "       [0.73544284, 0.35458851, 0.55158213, 0.1707278 ],\n",
       "       [0.73239618, 0.38547167, 0.53966034, 0.15418867],\n",
       "       [0.73446047, 0.37367287, 0.5411814 , 0.16750853],\n",
       "       [0.75728103, 0.3542121 , 0.52521104, 0.15878473],\n",
       "       [0.78258054, 0.38361791, 0.4603415 , 0.16879188],\n",
       "       [0.7431482 , 0.36505526, 0.5345452 , 0.16948994],\n",
       "       [0.65387747, 0.34250725, 0.62274045, 0.25947519],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.71491405, 0.30207636, 0.59408351, 0.21145345],\n",
       "       [0.69276796, 0.31889319, 0.61579374, 0.1979337 ],\n",
       "       [0.68619022, 0.31670318, 0.61229281, 0.232249  ],\n",
       "       [0.70953708, 0.28008043, 0.61617694, 0.1960563 ],\n",
       "       [0.67054118, 0.34211284, 0.61580312, 0.23263673],\n",
       "       [0.71366557, 0.28351098, 0.61590317, 0.17597233],\n",
       "       [0.71414125, 0.26647062, 0.61821183, 0.19185884],\n",
       "       [0.69198788, 0.34599394, 0.58626751, 0.24027357],\n",
       "       [0.71562645, 0.3523084 , 0.56149152, 0.22019275],\n",
       "       [0.71576546, 0.30196356, 0.59274328, 0.21249287],\n",
       "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
       "       [0.6925518 , 0.30375079, 0.60750157, 0.24300063],\n",
       "       [0.67767924, 0.32715549, 0.59589036, 0.28041899],\n",
       "       [0.69589887, 0.34794944, 0.57629125, 0.25008866],\n",
       "       [0.70610474, 0.3258945 , 0.59747324, 0.1955367 ],\n",
       "       [0.69299099, 0.34199555, 0.60299216, 0.19799743],\n",
       "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
       "       [0.72712585, 0.26661281, 0.60593821, 0.18178146],\n",
       "       [0.70558934, 0.32722984, 0.58287815, 0.23519645],\n",
       "       [0.68307923, 0.34153961, 0.59769433, 0.24395687],\n",
       "       [0.71486543, 0.25995106, 0.62202576, 0.18567933],\n",
       "       [0.73122464, 0.31338199, 0.56873028, 0.20892133],\n",
       "       [0.69595601, 0.3427843 , 0.59208198, 0.21813547],\n",
       "       [0.71529453, 0.31790868, 0.59607878, 0.17882363],\n",
       "       [0.72785195, 0.32870733, 0.56349829, 0.21131186],\n",
       "       [0.71171214, 0.35002236, 0.57170319, 0.21001342],\n",
       "       [0.69594002, 0.30447376, 0.60894751, 0.22835532],\n",
       "       [0.73089855, 0.30454106, 0.58877939, 0.1624219 ],\n",
       "       [0.72766159, 0.27533141, 0.59982915, 0.18683203],\n",
       "       [0.71578999, 0.34430405, 0.5798805 , 0.18121266],\n",
       "       [0.69417747, 0.30370264, 0.60740528, 0.2386235 ],\n",
       "       [0.72366005, 0.32162669, 0.58582004, 0.17230001],\n",
       "       [0.69385414, 0.29574111, 0.63698085, 0.15924521],\n",
       "       [0.73154399, 0.28501714, 0.57953485, 0.21851314],\n",
       "       [0.67017484, 0.36168166, 0.59571097, 0.2553047 ],\n",
       "       [0.69804799, 0.338117  , 0.59988499, 0.196326  ],\n",
       "       [0.71066905, 0.35533453, 0.56853524, 0.21320072],\n",
       "       [0.72415258, 0.32534391, 0.56672811, 0.22039426],\n",
       "       [0.69997037, 0.32386689, 0.58504986, 0.25073566],\n",
       "       [0.73337886, 0.32948905, 0.54206264, 0.24445962],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.69193502, 0.32561648, 0.60035539, 0.23403685],\n",
       "       [0.68914871, 0.33943145, 0.58629069, 0.25714504],\n",
       "       [0.72155725, 0.32308533, 0.56001458, 0.24769876],\n",
       "       [0.72965359, 0.28954508, 0.57909015, 0.22005426],\n",
       "       [0.71653899, 0.3307103 , 0.57323119, 0.22047353],\n",
       "       [0.67467072, 0.36998072, 0.58761643, 0.25028107],\n",
       "       [0.69025916, 0.35097923, 0.5966647 , 0.21058754]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data to help the model\n",
    "X = normalize(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now each row vector has unit length\n",
    "sum([x**2 for x in X[0, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split for test & training  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create and Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There's a lot of different parameters for `LogisticRegression`. Check out the documentation for more info: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_model = LogisticRegression(\n",
    "           C=1e3,              # Smaller values -> more regularization\n",
    "           max_iter=1e3,       # Ensure we eventually reach a solution\n",
    "           solver='lbfgs',     # (Default) Can optimize depending on problem\n",
    "           multi_class='auto'   # (Default) Will try to do multiclass classification \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, max_iter=1000.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit/Train the model\n",
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Evaluate the Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                    estimator=my_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97916667, 0.96875   , 0.95833333, 0.97916667, 0.96875   ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95833333, 1.        , 0.95833333, 0.95833333, 0.91666667])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cv_overall(cv_results):\n",
    "    val_results = cv_results['test_score']\n",
    "    result_str = f'{val_results.mean():.3f} Â± {val_results.std():.3f}'\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.958 Â± 0.026'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_overall(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's save these results for later\n",
    "models = {}\n",
    "\n",
    "models['model_1'] = {'model': my_model, 'cv':cv_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Overall Training Score\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py:499\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    Mean accuracy of self.predict(X) wrt. y.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:307\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m        Predicted class label per sample.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    309\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:280\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m        class would be predicted.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    284\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py:1019\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator)\n\u001b[1;32m   1016\u001b[0m              \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs:\n\u001b[0;32m-> 1019\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Overall Training Score\n",
    "my_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Rinse and Repeat - Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try out a few more models for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #2 with C=0.1\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.750 Â± 0.105\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.883\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #3 with C=100.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.950 Â± 0.017\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.967\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #4 with C=10000.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.958 Â± 0.026\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.975\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #5 with C=1000000.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.958 Â± 0.037\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.983\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust the regularization C\n",
    "c_values = [1e-1, 1e2, 1e4, 1e6]\n",
    "\n",
    "# Start at #2 since we have \"model_1\" already\n",
    "for i, c in enumerate(c_values, start=2):\n",
    "    \n",
    "    print(f'Model #{i} with C={c}')\n",
    "    new_model = LogisticRegression(C=c, max_iter=1e3)\n",
    "    \n",
    "    # Cross-validation\n",
    "    print('Cross-validating model with training data...')\n",
    "    cv_results = cross_validate(\n",
    "                    estimator=new_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    "    )\n",
    "    print(f'\\tCross-Validation Score: {cv_overall(cv_results)}')\n",
    "    \n",
    "    # Train/fit with the full training set\n",
    "    print('Fitting model to full training set...')\n",
    "    new_model.fit(X_train, y_train)\n",
    "    train_score = new_model.score(X_train, y_train)\n",
    "    print(f'\\tScore on training set: {train_score:.3f}')\n",
    "    \n",
    "    # Save results\n",
    "    print('Saving Results...')\n",
    "    models[f'model_{i}'] = {'model': new_model, 'cv': cv_results}\n",
    "    \n",
    "    print('\\n','-'*30,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000.0, max_iter=1000.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models['model_5']['model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's get predictions for training & testing sets\n",
    "y_hat_train = best_model.predict(X_train)\n",
    "y_hat_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Loss on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05988411574067338\n",
      "0.10115519548886272\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_train, best_model.predict_proba(X_train)))\n",
    "print(log_loss(y_test, best_model.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values correctly predicted:\n",
      "True     118\n",
      "False      2\n",
      "Name: target, dtype: int64\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Percentage of values correctly predicted: \n",
      "True     0.983333\n",
      "False    0.016667\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Was our model correct?\n",
    "residuals = y_train == y_hat_train\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values correctly predicted:\n",
      "True     28\n",
      "False     2\n",
      "Name: target, dtype: int64\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Percentage of values correctly predicted: \n",
      "True     0.933333\n",
      "False    0.066667\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the data below into train and test, and then convert the y-values (`geysers.kind`) into 1's and 0's. Then use `sklearn` to build a logistic regression model of whether Old Faithful's eruption wait time is long or short, based on the duration of the eruption. Finally, find the points in the test set where the model's prediction differs from the true y-value. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geysers = sns.load_dataset('geyser', **{'usecols': ['duration', 'kind']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   kind\n",
       "0     3.600   long\n",
       "1     1.800  short\n",
       "2     3.333   long\n",
       "3     2.283  short\n",
       "4     4.533   long"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration  kind \n",
       "1.867     short    8\n",
       "4.500     long     8\n",
       "1.833     short    7\n",
       "4.700     long     6\n",
       "4.800     long     6\n",
       "                  ..\n",
       "5.067     long     1\n",
       "3.833     short    1\n",
       "3.883     long     1\n",
       "3.966     long     1\n",
       "1.600     short    1\n",
       "Length: 128, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>kind</th>\n",
       "      <th>kind_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   kind  kind_converted\n",
       "0     3.600   long               1\n",
       "1     1.800  short               0\n",
       "2     3.333   long               1\n",
       "3     2.283  short               0\n",
       "4     4.533   long               1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers['kind_converted'] = geysers['kind'].map({'short':0, 'long':1})\n",
    "geysers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = geysers[['duration']]\n",
    "y = geysers['kind_converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration  kind   kind_converted\n",
       "1.867     short  0                 8\n",
       "4.500     long   1                 8\n",
       "1.833     short  0                 7\n",
       "4.700     long   1                 6\n",
       "4.800     long   1                 6\n",
       "                                  ..\n",
       "5.067     long   1                 1\n",
       "3.833     short  0                 1\n",
       "3.883     long   1                 1\n",
       "3.966     long   1                 1\n",
       "1.600     short  0                 1\n",
       "Length: 128, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    172\n",
       "0    100\n",
       "Name: kind_converted, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers['kind_converted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['long', 'short'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers['kind'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LogisticRegression(\n",
    "           C=1e3,              # Smaller values -> more regularization\n",
    "           max_iter=1e3,       # Ensure we eventually reach a solution\n",
    "           solver='lbfgs',     # (Default) Can optimize depending on problem\n",
    "           multi_class='auto'   # (Default) Will try to do multiclass classification \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, max_iter=1000.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit/Train the model\n",
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get predictions for training & testing sets\n",
    "y_hat_train = my_model.predict(X_train)\n",
    "y_hat_test = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05925961908311827\n",
      "0.09457446698868138\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_train, my_model.predict_proba(X_train)))\n",
    "print(log_loss(y_test, my_model.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values correctly predicted:\n",
      "True     53\n",
      "False     2\n",
      "Name: kind_converted, dtype: int64\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Percentage of values correctly predicted: \n",
      "True     0.963636\n",
      "False    0.036364\n",
      "Name: kind_converted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206     True\n",
       "197     True\n",
       "200     True\n",
       "65      True\n",
       "58      True\n",
       "134     True\n",
       "207     True\n",
       "5       True\n",
       "119     True\n",
       "88      True\n",
       "69      True\n",
       "211     True\n",
       "120     True\n",
       "48      True\n",
       "137     True\n",
       "166     True\n",
       "106     True\n",
       "268     True\n",
       "175     True\n",
       "245     True\n",
       "148     True\n",
       "115     True\n",
       "178     True\n",
       "49      True\n",
       "10      True\n",
       "152     True\n",
       "61      True\n",
       "188     True\n",
       "8       True\n",
       "156     True\n",
       "180     True\n",
       "59      True\n",
       "95      True\n",
       "172     True\n",
       "171     True\n",
       "140     True\n",
       "113     True\n",
       "70      True\n",
       "165     True\n",
       "241     True\n",
       "147     True\n",
       "38      True\n",
       "54      True\n",
       "154     True\n",
       "219     True\n",
       "37      True\n",
       "125     True\n",
       "183     True\n",
       "105     True\n",
       "97      True\n",
       "21      True\n",
       "214    False\n",
       "164    False\n",
       "238     True\n",
       "9       True\n",
       "Name: kind_converted, dtype: bool"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214    False\n",
       "164    False\n",
       "Name: kind_converted, dtype: bool"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals[residuals == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 272 entries, 0 to 271\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   duration        272 non-null    float64\n",
      " 1   kind            272 non-null    object \n",
      " 2   kind_converted  272 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.5+ KB\n"
     ]
    }
   ],
   "source": [
    "geysers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## More Generalizations: Other Link Functions, Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Logistic regression's link function is the logit function, but different sorts of models use different link functions.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function) has a nice table of generalized linear model types and their associated link functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
